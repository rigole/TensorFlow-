{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "01_neural_network_regression.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNdcwzsrP5ywwMCb04jMyUO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rigole/TensorFlow-/blob/main/01_neural_network_regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bAAVIaWTo9Rn"
      },
      "source": [
        "### Introduction to Regression with NN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gIc2Bm_FohfT"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1c_LZHxhp7ZZ"
      },
      "source": [
        "### Creating data to view and fit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "jx5raISvpKGP",
        "outputId": "c8d605f3-de46-419c-fe33-b6882cdd444c"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Create features\n",
        "X = np.array([-7.0, -4.0, -1.0, 2.0, 5.0, 8.0, 11.0, 14.0])\n",
        "\n",
        "# Create labels\n",
        "y = np.array([3.0, 6.0, 9.0, 12.0, 15.0, 18.0, 21, 24.0])\n",
        "\n",
        "# Visualize\n",
        "plt.scatter(X, y);"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "39vH4H85qqwC",
        "outputId": "d93c1d17-ee15-437c-9b17-19555ee0d5f9"
      },
      "source": [
        "y == X+10"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ True,  True,  True,  True,  True,  True,  True,  True])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QscgH0CcrBV7"
      },
      "source": [
        ""
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xeTIh8LXK11K"
      },
      "source": [
        "### Input and output shapes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JnctlQmxK5iK",
        "outputId": "1fd25ec1-2b90-42a9-9340-0cb5608f9d7e"
      },
      "source": [
        "# Create a demo tensor for our housing price prediction problem\n",
        "\n",
        "house_info = tf.constant([\"bedroom\", \"bathroom\", \"garage\"])\n",
        "house_price = tf.constant([939700])\n",
        "house_info, house_price"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(3,), dtype=string, numpy=array([b'bedroom', b'bathroom', b'garage'], dtype=object)>,\n",
              " <tf.Tensor: shape=(1,), dtype=int32, numpy=array([939700], dtype=int32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kdzluJ5-Lnw8",
        "outputId": "fcca709c-f781-4943-b756-dfa88a3e7189"
      },
      "source": [
        "input_shape = X.shape\n",
        "output_shape = y.shape\n",
        "input_shape, output_shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((8,), (8,))"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oeQJYXIANTzg",
        "outputId": "c3d2a266-0ab7-4a1e-d4fd-bd118ebf5a7c"
      },
      "source": [
        "X[0], y[0]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(-7.0, 3.0)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NFzx2ZchNWm8",
        "outputId": "3a7e69b2-7883-4df2-f047-4335dbc70cae"
      },
      "source": [
        "input_shape = X[0].shape\n",
        "output_shape = y[0].shape\n",
        "input_shape, output_shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((), ())"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qiyVmum3O6rU",
        "outputId": "ae273312-1300-45b9-d2dc-d2d1b8310cca"
      },
      "source": [
        "X[0].ndim"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_AUiKj3LPbOH",
        "outputId": "3d1b5d5b-e897-4f7c-a2d1-c1d1e0ff5bfe"
      },
      "source": [
        "# Turn our NumPy arrays into tensors\n",
        "X = tf.constant(X)\n",
        "y = tf.constant(y)\n",
        "X, X.shape, y, y.shape"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(8,), dtype=float64, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.])>,\n",
              " TensorShape([8]),\n",
              " <tf.Tensor: shape=(8,), dtype=float64, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.])>,\n",
              " TensorShape([8]))"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "58VpSeS8S3Ha",
        "outputId": "3b934013-2c98-4b10-ed5b-ce86d9af2933"
      },
      "source": [
        "input_shape = X[0].shape\n",
        "output_shape = y[0].shape\n",
        "input_shape, output_shape"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([]), TensorShape([]))"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "id": "AonB22DqTRZm",
        "outputId": "664589c9-b852-4983-f290-e4cec55f900b"
      },
      "source": [
        "plt.scatter(X, y)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7faed049f710>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DwjkwRYH6q1A",
        "outputId": "4f688bbd-1226-4096-b384-9568e0f8f239"
      },
      "source": [
        "X, y"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(8,), dtype=float64, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.])>,\n",
              " <tf.Tensor: shape=(8,), dtype=float64, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.])>)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 731
        },
        "id": "bkfl47AXTc-3",
        "outputId": "1d8c73eb-10ec-4c8d-b5d7-5b9d00b3da52"
      },
      "source": [
        "# Set random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "#1. Create a model using the sequential API\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(1),\n",
        "    \n",
        "])\n",
        "\n",
        " #2. Compile the model\n",
        "model.compile(loss=tf.keras.losses.mae,optimizer=tf.keras.optimizers.SGD(), \n",
        "              metrics=[\"mae\"]) # mae is for mean absolute error gd gradient descent\n",
        "\n",
        "\n",
        "# 3 Fit the model\n",
        "model.fit(X,y,epochs=5)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-0b4c43b0278c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# 3 Fit the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1127\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1128\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1129\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1130\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 878, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 867, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 860, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 808, in train_step\n        y_pred = self(x, training=True)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/input_spec.py\", line 227, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" '\n\n    ValueError: Exception encountered when calling layer \"sequential\" (type Sequential).\n    \n    Input 0 of layer \"dense\" is incompatible with the layer: expected min_ndim=2, found ndim=1. Full shape received: (None,)\n    \n    Call arguments received:\n      • inputs=tf.Tensor(shape=(None,), dtype=float64)\n      • training=True\n      • mask=None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JzUMt1QCY0qB",
        "outputId": "94bd9a3a-04c5-4426-c194-a55fdf9b96d1"
      },
      "source": [
        "# Set random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "#1. Create a model using the sequential API\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(1),\n",
        "    \n",
        "])\n",
        "\n",
        " #2. Compile the model\n",
        "model.compile(loss=tf.keras.losses.mae,optimizer=tf.keras.optimizers.SGD(), \n",
        "              metrics=[\"mae\"]) # mae is for mean absolute error gd gradient descent\n",
        "\n",
        "\n",
        "# 3 Fit the model\n",
        "model.fit(tf.expand_dims(X,axis=-1), y,epochs=5)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1/1 [==============================] - 1s 772ms/step - loss: 11.5048 - mae: 11.5048\n",
            "Epoch 2/5\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 11.3723 - mae: 11.3723\n",
            "Epoch 3/5\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 11.2398 - mae: 11.2398\n",
            "Epoch 4/5\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 11.1073 - mae: 11.1073\n",
            "Epoch 5/5\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 10.9748 - mae: 10.9748\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7faecfb3f410>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dVgp_NSt9Vxz",
        "outputId": "7303e5b1-37a4-4960-c9ce-a5110faf6eee"
      },
      "source": [
        "# Check out inputs and output\n",
        "X, y"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(8,), dtype=float64, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.])>,\n",
              " <tf.Tensor: shape=(8,), dtype=float64, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.])>)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vza2_QCi-Uds",
        "outputId": "0d35dd79-ec64-4212-b231-e65c693bc587"
      },
      "source": [
        "y_pred = model.predict([17.0])\n",
        "y_pred"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[12.716021]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YrBLwKxS_nCA"
      },
      "source": [
        "### Improving our model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dJ-Gs-I3_B6e",
        "outputId": "924ec354-e026-45ea-ecee-f0ec770cc283"
      },
      "source": [
        " # Rebuild the model by improving\n",
        "\n",
        " #1. Create a model again\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(1),\n",
        "    \n",
        "])\n",
        "\n",
        " #2. recompile the model\n",
        "model.compile(loss=tf.keras.losses.mae,optimizer=tf.keras.optimizers.SGD(), \n",
        "              metrics=[\"mae\"]) # mae is for mean absolute error gd gradient descent\n",
        "\n",
        "\n",
        "# 3 Fit the model and increase the epochs(and training it longer)\n",
        "model.fit(tf.expand_dims(X,axis=-1), y,epochs=100)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 0s 278ms/step - loss: 11.2219 - mae: 11.2219\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 11.0894 - mae: 11.0894\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 10.9569 - mae: 10.9569\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 10.8244 - mae: 10.8244\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 10.6919 - mae: 10.6919\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 10.5594 - mae: 10.5594\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 10.4269 - mae: 10.4269\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 10.2944 - mae: 10.2944\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 10.1619 - mae: 10.1619\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 10.0294 - mae: 10.0294\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 9.8969 - mae: 9.8969\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 9.7644 - mae: 9.7644\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 9.6319 - mae: 9.6319\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 9.4994 - mae: 9.4994\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 9.3669 - mae: 9.3669\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 9.2344 - mae: 9.2344\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 9.1019 - mae: 9.1019\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.9694 - mae: 8.9694\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 8.8369 - mae: 8.8369\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 8.7044 - mae: 8.7044\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.5719 - mae: 8.5719\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.4394 - mae: 8.4394\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 8.3069 - mae: 8.3069\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 8.1744 - mae: 8.1744\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.0419 - mae: 8.0419\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.9094 - mae: 7.9094\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.7769 - mae: 7.7769\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 7.6444 - mae: 7.6444\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.5119 - mae: 7.5119\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.3794 - mae: 7.3794\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.2750 - mae: 7.2750\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.2694 - mae: 7.2694\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.2638 - mae: 7.2638\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.2581 - mae: 7.2581\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.2525 - mae: 7.2525\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.2469 - mae: 7.2469\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.2412 - mae: 7.2412\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.2356 - mae: 7.2356\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.2300 - mae: 7.2300\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 7.2244 - mae: 7.2244\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.2188 - mae: 7.2188\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.2131 - mae: 7.2131\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.2075 - mae: 7.2075\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.2019 - mae: 7.2019\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 7.1962 - mae: 7.1962\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.1906 - mae: 7.1906\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.1850 - mae: 7.1850\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.1794 - mae: 7.1794\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.1737 - mae: 7.1737\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 7.1681 - mae: 7.1681\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.1625 - mae: 7.1625\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.1569 - mae: 7.1569\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 7.1512 - mae: 7.1512\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 7.1456 - mae: 7.1456\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.1400 - mae: 7.1400\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.1344 - mae: 7.1344\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.1287 - mae: 7.1287\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 7.1231 - mae: 7.1231\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.1175 - mae: 7.1175\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.1119 - mae: 7.1119\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.1062 - mae: 7.1062\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.1006 - mae: 7.1006\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.0950 - mae: 7.0950\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.0894 - mae: 7.0894\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 7.0838 - mae: 7.0838\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.0781 - mae: 7.0781\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.0725 - mae: 7.0725\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.0669 - mae: 7.0669\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.0613 - mae: 7.0613\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.0556 - mae: 7.0556\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.0500 - mae: 7.0500\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.0444 - mae: 7.0444\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.0388 - mae: 7.0388\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.0331 - mae: 7.0331\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.0275 - mae: 7.0275\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.0219 - mae: 7.0219\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.0163 - mae: 7.0163\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 7.0106 - mae: 7.0106\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.0050 - mae: 7.0050\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 6.9994 - mae: 6.9994\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.9938 - mae: 6.9938\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 6.9881 - mae: 6.9881\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 6.9825 - mae: 6.9825\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.9769 - mae: 6.9769\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 6.9713 - mae: 6.9713\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.9656 - mae: 6.9656\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.9600 - mae: 6.9600\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 6.9544 - mae: 6.9544\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 6.9488 - mae: 6.9488\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.9431 - mae: 6.9431\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 6.9375 - mae: 6.9375\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.9319 - mae: 6.9319\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 6.9263 - mae: 6.9263\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 6.9206 - mae: 6.9206\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.9150 - mae: 6.9150\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 6.9094 - mae: 6.9094\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.9038 - mae: 6.9038\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.8981 - mae: 6.8981\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 6.8925 - mae: 6.8925\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.8869 - mae: 6.8869\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7faecfadc610>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MduXXYgxMDOd",
        "outputId": "8071986c-81a9-456a-9938-9278892e560b"
      },
      "source": [
        "# Checking the progression of the model\n",
        "model.predict([17.0])"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[29.739855]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "47f2Kqf5M_5i",
        "outputId": "4a6953b2-d57e-4c98-91d1-b57ceb3b3c82"
      },
      "source": [
        "# Rebuild the model for the third time by adding a new layer and activation\n",
        "\n",
        " #1. Create a model again\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(100, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(100, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(1)\n",
        "    \n",
        "])\n",
        "\n",
        " #2. recompile the model\n",
        "model.compile(loss=tf.keras.losses.mae,optimizer=tf.keras.optimizers.SGD(), \n",
        "              metrics=[\"mae\"]) # mae is for mean absolute error gd gradient descent\n",
        "\n",
        "\n",
        "# 3 Fit the model and keeping the epochs\n",
        "model.fit(tf.expand_dims(X,axis=-1), y,epochs=100)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 0s 371ms/step - loss: 14.1593 - mae: 14.1593\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 13.5106 - mae: 13.5106\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 12.8859 - mae: 12.8859\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 12.3149 - mae: 12.3149\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 11.7463 - mae: 11.7463\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 11.1240 - mae: 11.1240\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 10.4452 - mae: 10.4452\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 9.6973 - mae: 9.6973\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.8439 - mae: 8.8439\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.8758 - mae: 7.8758\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.8512 - mae: 6.8512\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.6212 - mae: 5.6212\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 4.1683 - mae: 4.1683\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.9993 - mae: 3.9993\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.9496 - mae: 3.9496\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.9630 - mae: 3.9630\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.9589 - mae: 3.9589\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.9243 - mae: 3.9243\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.9698 - mae: 3.9698\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.8867 - mae: 3.8867\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.9797 - mae: 3.9797\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.8471 - mae: 3.8471\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.9911 - mae: 3.9911\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.8564 - mae: 3.8564\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.9589 - mae: 3.9589\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.8890 - mae: 3.8890\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.9046 - mae: 3.9046\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.9013 - mae: 3.9013\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.8634 - mae: 3.8634\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.9141 - mae: 3.9141\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.8215 - mae: 3.8215\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.9272 - mae: 3.9272\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.7959 - mae: 3.7959\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.9324 - mae: 3.9324\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.8295 - mae: 3.8295\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.8737 - mae: 3.8737\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.8426 - mae: 3.8426\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.8305 - mae: 3.8305\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.8563 - mae: 3.8563\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.7867 - mae: 3.7867\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.8707 - mae: 3.8707\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.7427 - mae: 3.7427\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.8853 - mae: 3.8853\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.7667 - mae: 3.7667\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.8335 - mae: 3.8335\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.7874 - mae: 3.7874\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.7870 - mae: 3.7870\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.8021 - mae: 3.8021\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.7414 - mae: 3.7414\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.8169 - mae: 3.8169\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.6953 - mae: 3.6953\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.8327 - mae: 3.8327\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.7146 - mae: 3.7146\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.7852 - mae: 3.7852\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.7403 - mae: 3.7403\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.7376 - mae: 3.7376\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.7557 - mae: 3.7557\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.6893 - mae: 3.6893\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.7722 - mae: 3.7722\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.6465 - mae: 3.6465\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.7931 - mae: 3.7931\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.6840 - mae: 3.6840\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.7285 - mae: 3.7285\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.6998 - mae: 3.6998\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.6789 - mae: 3.6789\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.7165 - mae: 3.7165\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.6295 - mae: 3.6295\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.7331 - mae: 3.7331\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.6074 - mae: 3.6074\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.7315 - mae: 3.7315\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.6447 - mae: 3.6447\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.6632 - mae: 3.6632\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.6618 - mae: 3.6618\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.6115 - mae: 3.6115\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.6796 - mae: 3.6796\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.5596 - mae: 3.5596\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.6983 - mae: 3.6983\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.5736 - mae: 3.5736\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.6580 - mae: 3.6580\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.6140 - mae: 3.6140\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.5917 - mae: 3.5917\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.6320 - mae: 3.6320\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.5375 - mae: 3.5375\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.6508 - mae: 3.6508\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.5279 - mae: 3.5279\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.6200 - mae: 3.6200\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 3.5462 - mae: 3.5462\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.5776 - mae: 3.5776\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.5868 - mae: 3.5868\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.5082 - mae: 3.5082\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.6059 - mae: 3.6059\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.4842 - mae: 3.4842\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.5879 - mae: 3.5879\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.5033 - mae: 3.5033\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.5314 - mae: 3.5314\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.5222 - mae: 3.5222\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.4820 - mae: 3.4820\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.5647 - mae: 3.5647\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 3.4452 - mae: 3.4452\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.5508 - mae: 3.5508\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7faecf9cd9d0>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K_1OZA--OC6b",
        "outputId": "dd2c73cf-4d69-4b16-8009-c14cd734fbb9"
      },
      "source": [
        "# Checking the progression of the model again\n",
        "model.predict([17.0])"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[32.258904]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I276PbjROHiV",
        "outputId": "e1524e80-db03-4ffc-da2c-c54453a438b5"
      },
      "source": [
        "# An other change to our model(one extra layer with 100 unit)\n",
        " #1. Create a model again\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(100, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(1)\n",
        "    \n",
        "])\n",
        "\n",
        " #2. recompile the model\n",
        "model.compile(loss=\"mae\",\n",
        "              optimizer=tf.keras.optimizers.SGD(), \n",
        "              metrics=[\"mae\"])\n",
        "\n",
        "\n",
        "# 3 Fit the model and keeping the epochs\n",
        "model.fit(tf.expand_dims(X,axis=-1), y,epochs=100)\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 0s 304ms/step - loss: 13.5267 - mae: 13.5267\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 12.9594 - mae: 12.9594\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 12.3983 - mae: 12.3983\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 11.8281 - mae: 11.8281\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 11.2463 - mae: 11.2463\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 10.6465 - mae: 10.6465\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 10.0294 - mae: 10.0294\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 9.3938 - mae: 9.3938\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.7211 - mae: 8.7211\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.0110 - mae: 8.0110\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.2573 - mae: 7.2573\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.4531 - mae: 6.4531\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 5.5874 - mae: 5.5874\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 4.6583 - mae: 4.6583\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 4.0382 - mae: 4.0382\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.9405 - mae: 3.9405\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.9362 - mae: 3.9362\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 3.9147 - mae: 3.9147\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.9427 - mae: 3.9427\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.8977 - mae: 3.8977\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.9583 - mae: 3.9583\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.8904 - mae: 3.8904\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.9447 - mae: 3.9447\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.8969 - mae: 3.8969\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.9188 - mae: 3.9188\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.9035 - mae: 3.9035\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.8928 - mae: 3.8928\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.9169 - mae: 3.9169\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.8749 - mae: 3.8749\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.9260 - mae: 3.9260\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.8586 - mae: 3.8586\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.9219 - mae: 3.9219\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.8653 - mae: 3.8653\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.8958 - mae: 3.8958\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.8721 - mae: 3.8721\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.8744 - mae: 3.8744\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.8879 - mae: 3.8879\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.8513 - mae: 3.8513\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.8949 - mae: 3.8949\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.8279 - mae: 3.8279\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.8978 - mae: 3.8978\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.8348 - mae: 3.8348\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.8714 - mae: 3.8714\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.8443 - mae: 3.8443\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.8531 - mae: 3.8531\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.8579 - mae: 3.8579\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.8263 - mae: 3.8263\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.8651 - mae: 3.8651\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.7994 - mae: 3.7994\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.8724 - mae: 3.8724\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.8054 - mae: 3.8054\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.8462 - mae: 3.8462\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.8216 - mae: 3.8216\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.8271 - mae: 3.8271\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.8289 - mae: 3.8289\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.8000 - mae: 3.8000\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.8363 - mae: 3.8363\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.7728 - mae: 3.7728\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.8438 - mae: 3.8438\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.7772 - mae: 3.7772\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.8254 - mae: 3.8254\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.7935 - mae: 3.7935\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.7998 - mae: 3.7998\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.8010 - mae: 3.8010\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.7724 - mae: 3.7724\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.8086 - mae: 3.8086\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.7449 - mae: 3.7449\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.8163 - mae: 3.8163\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.7538 - mae: 3.7538\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.7987 - mae: 3.7987\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.7664 - mae: 3.7664\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.7711 - mae: 3.7711\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.7741 - mae: 3.7741\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.7435 - mae: 3.7435\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.7819 - mae: 3.7819\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.7162 - mae: 3.7162\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.7899 - mae: 3.7899\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.7327 - mae: 3.7327\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.7690 - mae: 3.7690\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 3.7405 - mae: 3.7405\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.7411 - mae: 3.7411\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.7484 - mae: 3.7484\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.7132 - mae: 3.7132\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.7564 - mae: 3.7564\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.6909 - mae: 3.6909\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.7650 - mae: 3.7650\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.7077 - mae: 3.7077\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.7380 - mae: 3.7380\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.7156 - mae: 3.7156\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.7098 - mae: 3.7098\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.7236 - mae: 3.7236\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.6815 - mae: 3.6815\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.7318 - mae: 3.7318\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.6710 - mae: 3.6710\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.7340 - mae: 3.7340\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.6835 - mae: 3.6835\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.7056 - mae: 3.7056\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.6916 - mae: 3.6916\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.6771 - mae: 3.6771\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.6999 - mae: 3.6999\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7faeceb7bb10>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U1UFX6FRSkOw",
        "outputId": "8a1ff07a-0332-4d27-c6e3-ae4c95e887fd"
      },
      "source": [
        "# Let'stry to make a production\n",
        "model.predict([17.0])"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[31.824467]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rt5W6tc7TALE",
        "outputId": "53fed570-3e16-4d0c-8832-00994ece9f49"
      },
      "source": [
        "# An other change to our model()\n",
        " #1. Create a model again\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(500, activation=None),\n",
        "    tf.keras.layers.Dense(1)\n",
        "    \n",
        "])\n",
        "\n",
        " #2. recompile the model\n",
        "model.compile(loss=\"mae\",\n",
        "              optimizer=tf.keras.optimizers.SGD(), \n",
        "              metrics=[\"mae\"])\n",
        "\n",
        "\n",
        "# 3 Fit the model and keeping the epochs\n",
        "model.fit(tf.expand_dims(X,axis=-1), y,epochs=100)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 0s 312ms/step - loss: 13.1164 - mae: 13.1164\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 12.5770 - mae: 12.5770\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 12.0342 - mae: 12.0342\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 11.4852 - mae: 11.4852\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 10.9271 - mae: 10.9271\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 10.3570 - mae: 10.3570\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 9.7719 - mae: 9.7719\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 9.1690 - mae: 9.1690\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 8.5451 - mae: 8.5451\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.8970 - mae: 7.8970\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.2427 - mae: 7.2427\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.2218 - mae: 7.2218\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.2008 - mae: 7.2008\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.1798 - mae: 7.1798\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.1587 - mae: 7.1587\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.1376 - mae: 7.1376\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.1164 - mae: 7.1164\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.0952 - mae: 7.0952\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.0739 - mae: 7.0739\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.0525 - mae: 7.0525\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 7.0311 - mae: 7.0311\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.0096 - mae: 7.0096\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 6.9880 - mae: 6.9880\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 6.9663 - mae: 6.9663\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.9445 - mae: 6.9445\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.9227 - mae: 6.9227\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.9008 - mae: 6.9008\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.8787 - mae: 6.8787\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 6.8566 - mae: 6.8566\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.8343 - mae: 6.8343\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 6.8120 - mae: 6.8120\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.7896 - mae: 6.7896\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 6.7670 - mae: 6.7670\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 6.7443 - mae: 6.7443\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.7215 - mae: 6.7215\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.6985 - mae: 6.6985\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.6755 - mae: 6.6755\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.6523 - mae: 6.6523\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 6.6289 - mae: 6.6289\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.6055 - mae: 6.6055\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.5818 - mae: 6.5818\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.5581 - mae: 6.5581\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.5341 - mae: 6.5341\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.5100 - mae: 6.5100\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 6.4858 - mae: 6.4858\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 6.4674 - mae: 6.4674\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.4571 - mae: 6.4571\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 6.4329 - mae: 6.4329\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 6.4086 - mae: 6.4086\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 6.3841 - mae: 6.3841\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.3594 - mae: 6.3594\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 6.3345 - mae: 6.3345\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 6.3094 - mae: 6.3094\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 6.2842 - mae: 6.2842\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.2587 - mae: 6.2587\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 6.2330 - mae: 6.2330\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 6.2071 - mae: 6.2071\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 6.1810 - mae: 6.1810\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 6.1547 - mae: 6.1547\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 6.1282 - mae: 6.1282\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 6.1014 - mae: 6.1014\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.0744 - mae: 6.0744\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.0472 - mae: 6.0472\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.0197 - mae: 6.0197\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.9919 - mae: 5.9919\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.9821 - mae: 5.9821\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.9617 - mae: 5.9617\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 5.9339 - mae: 5.9339\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 5.9057 - mae: 5.9057\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.8773 - mae: 5.8773\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 5.8486 - mae: 5.8486\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 5.8197 - mae: 5.8197\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 5.7904 - mae: 5.7904\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 5.7609 - mae: 5.7609\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 5.7311 - mae: 5.7311\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 5.7009 - mae: 5.7009\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 5.6705 - mae: 5.6705\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.6398 - mae: 5.6398\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.6087 - mae: 5.6087\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.5773 - mae: 5.5773\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.5456 - mae: 5.5456\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 5.5169 - mae: 5.5169\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.5679 - mae: 5.5679\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.6280 - mae: 5.6280\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.4433 - mae: 5.4433\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 5.4104 - mae: 5.4104\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 5.3772 - mae: 5.3772\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 5.3436 - mae: 5.3436\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 5.3097 - mae: 5.3097\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 5.2753 - mae: 5.2753\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 5.2406 - mae: 5.2406\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.2055 - mae: 5.2055\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.1700 - mae: 5.1700\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 5.1539 - mae: 5.1539\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.2226 - mae: 5.2226\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.2690 - mae: 5.2690\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.0549 - mae: 5.0549\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 5.0179 - mae: 5.0179\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 4.9805 - mae: 4.9805\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 4.9426 - mae: 4.9426\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7faecf916050>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lHu0L04XWMTk",
        "outputId": "d9faeb93-e979-4edf-8ab8-b8dc844f4995"
      },
      "source": [
        "# Let's try an other prediction\n",
        "model.predict([17.0])"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[29.83589]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AGdrN1HsRT5Z",
        "outputId": "ac0b3b08-b67d-46f9-cf15-7ccc48ccc98d"
      },
      "source": [
        "# An other change to our model()\n",
        " #1. Create a model again\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(500, activation=None),\n",
        "    tf.keras.layers.Dense(1)\n",
        "    \n",
        "])\n",
        "\n",
        " #2. recompile the model\n",
        "model.compile(loss=\"mae\",\n",
        "              optimizer=tf.keras.optimizers.Adam(), \n",
        "              metrics=[\"mae\"])\n",
        "\n",
        "\n",
        "# 3 Fit the model and keeping the epochs\n",
        "model.fit(tf.expand_dims(X,axis=-1), y,epochs=100)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 0s 356ms/step - loss: 13.3344 - mae: 13.3344\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 13.1126 - mae: 13.1126\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 12.8908 - mae: 12.8908\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 12.6688 - mae: 12.6688\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 12.4466 - mae: 12.4466\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 12.2241 - mae: 12.2241\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 12.0011 - mae: 12.0011\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 11.7775 - mae: 11.7775\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 11.5533 - mae: 11.5533\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 11.3283 - mae: 11.3283\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 11.1024 - mae: 11.1024\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 10.8755 - mae: 10.8755\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 10.6475 - mae: 10.6475\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 10.4181 - mae: 10.4181\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 10.1873 - mae: 10.1873\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 9.9549 - mae: 9.9549\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 9.7207 - mae: 9.7207\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 9.4847 - mae: 9.4847\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 9.2466 - mae: 9.2466\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 9.0063 - mae: 9.0063\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.7636 - mae: 8.7636\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 8.5184 - mae: 8.5184\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.2706 - mae: 8.2706\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.0199 - mae: 8.0199\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.7663 - mae: 7.7663\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.5095 - mae: 7.5095\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.2495 - mae: 7.2495\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.9860 - mae: 6.9860\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.8332 - mae: 6.8332\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.8039 - mae: 6.8039\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.7748 - mae: 6.7748\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.8335 - mae: 6.8335\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 6.9246 - mae: 6.9246\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.9886 - mae: 6.9886\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.0281 - mae: 7.0281\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.0455 - mae: 7.0455\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.0431 - mae: 7.0431\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.0228 - mae: 7.0228\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.9868 - mae: 6.9868\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.9366 - mae: 6.9366\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 6.8741 - mae: 6.8741\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.8006 - mae: 6.8006\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.7175 - mae: 6.7175\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.6259 - mae: 6.6259\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 6.5271 - mae: 6.5271\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 6.4570 - mae: 6.4570\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.4408 - mae: 6.4408\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.4235 - mae: 6.4235\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.4053 - mae: 6.4053\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.3862 - mae: 6.3862\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 6.3664 - mae: 6.3664\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 6.3457 - mae: 6.3457\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 6.3243 - mae: 6.3243\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 6.3105 - mae: 6.3105\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.2921 - mae: 6.2921\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 6.2502 - mae: 6.2502\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 6.2227 - mae: 6.2227\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.1948 - mae: 6.1948\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 6.1665 - mae: 6.1665\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 6.1378 - mae: 6.1378\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.1087 - mae: 6.1087\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.0793 - mae: 6.0793\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.0494 - mae: 6.0494\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.0190 - mae: 6.0190\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.9883 - mae: 5.9883\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.9570 - mae: 5.9570\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.9254 - mae: 5.9254\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 5.8932 - mae: 5.8932\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 5.8605 - mae: 5.8605\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.8274 - mae: 5.8274\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 5.7937 - mae: 5.7937\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.7595 - mae: 5.7595\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 5.7247 - mae: 5.7247\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 5.6894 - mae: 5.6894\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.6535 - mae: 5.6535\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.6336 - mae: 5.6336\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 5.6025 - mae: 5.6025\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.5531 - mae: 5.5531\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 5.5200 - mae: 5.5200\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 5.4883 - mae: 5.4883\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.4554 - mae: 5.4554\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.4213 - mae: 5.4213\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.3862 - mae: 5.3862\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 5.3499 - mae: 5.3499\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.3126 - mae: 5.3126\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 5.2743 - mae: 5.2743\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.2349 - mae: 5.2349\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.1946 - mae: 5.1946\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 5.1533 - mae: 5.1533\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.1110 - mae: 5.1110\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.0677 - mae: 5.0677\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.0235 - mae: 5.0235\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.9783 - mae: 4.9783\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.9321 - mae: 4.9321\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.8850 - mae: 4.8850\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 4.8369 - mae: 4.8369\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.7879 - mae: 4.7879\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 4.7602 - mae: 4.7602\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 4.7091 - mae: 4.7091\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.6454 - mae: 4.6454\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7faec89b5310>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f3FwxQVNRwwQ",
        "outputId": "6bbb960c-c462-41de-ec17-188b634360d6"
      },
      "source": [
        "# An other change to our model()\n",
        " #1. Create a model again by increasing the learning rate of ADAM\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(500, activation=None),\n",
        "    tf.keras.layers.Dense(1)\n",
        "    \n",
        "])\n",
        "\n",
        " #2. recompile the model\n",
        "model.compile(loss=\"mae\",\n",
        "              optimizer=tf.keras.optimizers.Adam(learning_rate=0.01), \n",
        "              metrics=[\"mae\"])\n",
        "\n",
        "\n",
        "# 3 Fit the model and keeping the epochs\n",
        "model.fit(tf.expand_dims(X,axis=-1), y,epochs=100)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 0s 350ms/step - loss: 12.9791 - mae: 12.9791\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 10.7870 - mae: 10.7870\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.5588 - mae: 8.5588\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.8404 - mae: 6.8404\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 8.4602 - mae: 8.4602\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.6841 - mae: 8.6841\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 7.9698 - mae: 7.9698\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.8248 - mae: 6.8248\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.0393 - mae: 6.0393\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.1096 - mae: 6.1096\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.2178 - mae: 6.2178\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.9456 - mae: 5.9456\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.3577 - mae: 5.3577\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.9953 - mae: 4.9953\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.9803 - mae: 4.9803\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 4.8229 - mae: 4.8229\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.5317 - mae: 4.5317\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.1138 - mae: 4.1138\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.5746 - mae: 3.5746\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.1005 - mae: 3.1005\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.0718 - mae: 3.0718\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.6416 - mae: 2.6416\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.7827 - mae: 1.7827\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.4900 - mae: 1.4900\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.4014 - mae: 1.4014\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6794 - mae: 0.6794\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.1387 - mae: 1.1387\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.7773 - mae: 1.7773\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.7113 - mae: 1.7113\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.8327 - mae: 1.8327\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.0217 - mae: 2.0217\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.6547 - mae: 1.6547\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.4740 - mae: 1.4740\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.3676 - mae: 1.3676\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.8928 - mae: 0.8928\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.3861 - mae: 0.3861\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5105 - mae: 0.5105\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5217 - mae: 0.5217\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.0126 - mae: 1.0126\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.1278 - mae: 1.1278\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.8681 - mae: 0.8681\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0163 - mae: 1.0163\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.1962 - mae: 1.1962\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.8901 - mae: 0.8901\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2331 - mae: 0.2331\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5658 - mae: 0.5658\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5808 - mae: 0.5808\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4570 - mae: 0.4570\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5511 - mae: 0.5511\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.4008 - mae: 0.4008\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2500 - mae: 0.2500\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.3079 - mae: 0.3079\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1847 - mae: 0.1847\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5586 - mae: 0.5586\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6167 - mae: 0.6167\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.3098 - mae: 0.3098\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.4747 - mae: 0.4747\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5446 - mae: 0.5446\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2509 - mae: 0.2509\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.8249 - mae: 0.8249\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0033 - mae: 1.0033\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6463 - mae: 0.6463\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1859 - mae: 0.1859\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.4076 - mae: 0.4076\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1636 - mae: 0.1636\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4212 - mae: 0.4212\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.3275 - mae: 0.3275\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2101 - mae: 0.2101\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2327 - mae: 0.2327\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2727 - mae: 0.2727\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1374 - mae: 0.1374\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4235 - mae: 0.4235\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.4253 - mae: 0.4253\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.2422 - mae: 0.2422\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.2766 - mae: 0.2766\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0689 - mae: 0.0689\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.2180 - mae: 0.2180\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2033 - mae: 0.2033\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2240 - mae: 0.2240\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1528 - mae: 0.1528\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0972 - mae: 0.0972\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.2485 - mae: 0.2485\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.1286 - mae: 0.1286\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1087 - mae: 0.1087\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.2480 - mae: 0.2480\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2194 - mae: 0.2194\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.4336 - mae: 0.4336\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.3584 - mae: 0.3584\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1813 - mae: 0.1813\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1830 - mae: 0.1830\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2857 - mae: 0.2857\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2912 - mae: 0.2912\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1564 - mae: 0.1564\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1277 - mae: 0.1277\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.3484 - mae: 0.3484\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2674 - mae: 0.2674\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.2913 - mae: 0.2913\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.3221 - mae: 0.3221\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.2085 - mae: 0.2085\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1890 - mae: 0.1890\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7faeca137910>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "auMzwVINSOvF",
        "outputId": "44f16e03-361d-46de-caea-d5a55667f138"
      },
      "source": [
        "#let's make a prediction\n",
        "model.predict([17.0])"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:6 out of the last 7 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7faec891e440> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[27.590809]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_cw4i7_aStzw",
        "outputId": "f7d29e13-e67b-4d57-da13-3bf88f869e4e"
      },
      "source": [
        "#let's make an other prediction\n",
        "model.predict([19.0])"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[29.645197]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6w1ByAdNT1EN"
      },
      "source": [
        "### Evaluating a Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rIETa0tqS0km",
        "outputId": "16f08520-3615-4c1a-fa8e-beb106f44942"
      },
      "source": [
        "# Make a bigger dataset\n",
        "X = tf.range(-100, 100, 4)\n",
        "X"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(50,), dtype=int32, numpy=\n",
              "array([-100,  -96,  -92,  -88,  -84,  -80,  -76,  -72,  -68,  -64,  -60,\n",
              "        -56,  -52,  -48,  -44,  -40,  -36,  -32,  -28,  -24,  -20,  -16,\n",
              "        -12,   -8,   -4,    0,    4,    8,   12,   16,   20,   24,   28,\n",
              "         32,   36,   40,   44,   48,   52,   56,   60,   64,   68,   72,\n",
              "         76,   80,   84,   88,   92,   96], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5n8J5crTW0Cz",
        "outputId": "da0f01e4-8614-45a1-9340-57031c986cde"
      },
      "source": [
        "# Make labels for the dataset\n",
        "y = X + 10\n",
        "y"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(50,), dtype=int32, numpy=\n",
              "array([-90, -86, -82, -78, -74, -70, -66, -62, -58, -54, -50, -46, -42,\n",
              "       -38, -34, -30, -26, -22, -18, -14, -10,  -6,  -2,   2,   6,  10,\n",
              "        14,  18,  22,  26,  30,  34,  38,  42,  46,  50,  54,  58,  62,\n",
              "        66,  70,  74,  78,  82,  86,  90,  94,  98, 102, 106], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "xrDbm0XfXUuD",
        "outputId": "240ff136-6c75-4b7d-9287-698009fbe693"
      },
      "source": [
        "# Visualize the data\n",
        "import matplotlib.pyplot as plt\n",
        "plt.scatter(X, y)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7faeca056810>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-YaRdAChX4KN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}