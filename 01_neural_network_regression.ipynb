{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "01_neural_network_regression.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "bAAVIaWTo9Rn",
        "1c_LZHxhp7ZZ"
      ],
      "authorship_tag": "ABX9TyNBW8RqSmBCAcjZD2t5DZ1H",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rigole/TensorFlow-/blob/main/01_neural_network_regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bAAVIaWTo9Rn"
      },
      "source": [
        "### Introduction to Regression with NN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gIc2Bm_FohfT"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1c_LZHxhp7ZZ"
      },
      "source": [
        "### Creating data to view and fit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "jx5raISvpKGP",
        "outputId": "4b7104af-f1c6-430e-d457-ebf71da67c09"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Create features\n",
        "X = np.array([-7.0, -4.0, -1.0, 2.0, 5.0, 8.0, 11.0, 14.0])\n",
        "\n",
        "# Create labels\n",
        "y = np.array([3.0, 6.0, 9.0, 12.0, 15.0, 18.0, 21, 24.0])\n",
        "\n",
        "# Visualize\n",
        "plt.scatter(X, y);"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "39vH4H85qqwC",
        "outputId": "5096a942-5822-44d2-dbec-54b072bf10f2"
      },
      "source": [
        "y == X+10"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ True,  True,  True,  True,  True,  True,  True,  True])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QscgH0CcrBV7"
      },
      "source": [
        ""
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xeTIh8LXK11K"
      },
      "source": [
        "### Input and output shapes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JnctlQmxK5iK",
        "outputId": "009f9933-44fa-45b3-b798-6d509a44ee51"
      },
      "source": [
        "# Create a demo tensor for our housing price prediction problem\n",
        "\n",
        "house_info = tf.constant([\"bedroom\", \"bathroom\", \"garage\"])\n",
        "house_price = tf.constant([939700])\n",
        "house_info, house_price"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(3,), dtype=string, numpy=array([b'bedroom', b'bathroom', b'garage'], dtype=object)>,\n",
              " <tf.Tensor: shape=(1,), dtype=int32, numpy=array([939700], dtype=int32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kdzluJ5-Lnw8",
        "outputId": "4f32baab-0e01-4ca3-c41c-0fda6b098f0a"
      },
      "source": [
        "input_shape = X.shape\n",
        "output_shape = y.shape\n",
        "input_shape, output_shape"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((8,), (8,))"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oeQJYXIANTzg",
        "outputId": "096d627a-8040-4a2d-bf60-68b1e89593d1"
      },
      "source": [
        "X[0], y[0]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(-7.0, 3.0)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NFzx2ZchNWm8",
        "outputId": "766b01d6-5e27-49ad-9aee-5cb7db190919"
      },
      "source": [
        "input_shape = X[0].shape\n",
        "output_shape = y[0].shape\n",
        "input_shape, output_shape"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((), ())"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qiyVmum3O6rU",
        "outputId": "40a29441-0e0c-449b-8438-ef3866a0c0ab"
      },
      "source": [
        "X[0].ndim"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_AUiKj3LPbOH",
        "outputId": "a84cf762-3d98-4c11-9a11-0758311de876"
      },
      "source": [
        "# Turn our NumPy arrays into tensors\n",
        "X = tf.constant(X)\n",
        "y = tf.constant(y)\n",
        "X, X.shape, y, y.shape"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(8,), dtype=float64, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.])>,\n",
              " TensorShape([8]),\n",
              " <tf.Tensor: shape=(8,), dtype=float64, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.])>,\n",
              " TensorShape([8]))"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "58VpSeS8S3Ha",
        "outputId": "864275fc-4228-46ea-ee52-6db9ad3de9d2"
      },
      "source": [
        "input_shape = X[0].shape\n",
        "output_shape = y[0].shape\n",
        "input_shape, output_shape"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([]), TensorShape([]))"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "id": "AonB22DqTRZm",
        "outputId": "d7247b89-a6e0-415d-e7b2-955c47c3c777"
      },
      "source": [
        "plt.scatter(X, y)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7f375b304850>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DwjkwRYH6q1A",
        "outputId": "fc179a62-a1d9-4278-9ef1-9d940ff269f3"
      },
      "source": [
        "X, y"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(8,), dtype=float64, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.])>,\n",
              " <tf.Tensor: shape=(8,), dtype=float64, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.])>)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 731
        },
        "id": "bkfl47AXTc-3",
        "outputId": "a948d468-17a0-4171-8d35-c72ff7eb4e5c"
      },
      "source": [
        "# Set random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "#1. Create a model using the sequential API\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(1),\n",
        "    \n",
        "])\n",
        "\n",
        " #2. Compile the model\n",
        "model.compile(loss=tf.keras.losses.mae,optimizer=tf.keras.optimizers.SGD(), \n",
        "              metrics=[\"mae\"]) # mae is for mean absolute error gd gradient descent\n",
        "\n",
        "\n",
        "# 3 Fit the model\n",
        "model.fit(X,y,epochs=5)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-0b4c43b0278c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# 3 Fit the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1127\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1128\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1129\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1130\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 878, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 867, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 860, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 808, in train_step\n        y_pred = self(x, training=True)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/input_spec.py\", line 227, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" '\n\n    ValueError: Exception encountered when calling layer \"sequential\" (type Sequential).\n    \n    Input 0 of layer \"dense\" is incompatible with the layer: expected min_ndim=2, found ndim=1. Full shape received: (None,)\n    \n    Call arguments received:\n      • inputs=tf.Tensor(shape=(None,), dtype=float64)\n      • training=True\n      • mask=None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JzUMt1QCY0qB",
        "outputId": "4affd324-e8fc-46ec-9df4-e24cd470e1d3"
      },
      "source": [
        "# Set random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "#1. Create a model using the sequential API\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(1),\n",
        "    \n",
        "])\n",
        "\n",
        " #2. Compile the model\n",
        "model.compile(loss=tf.keras.losses.mae,optimizer=tf.keras.optimizers.SGD(), \n",
        "              metrics=[\"mae\"]) # mae is for mean absolute error gd gradient descent\n",
        "\n",
        "\n",
        "# 3 Fit the model\n",
        "model.fit(tf.expand_dims(X,axis=-1), y,epochs=5)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1/1 [==============================] - 1s 513ms/step - loss: 11.5048 - mae: 11.5048\n",
            "Epoch 2/5\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 11.3723 - mae: 11.3723\n",
            "Epoch 3/5\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 11.2398 - mae: 11.2398\n",
            "Epoch 4/5\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 11.1073 - mae: 11.1073\n",
            "Epoch 5/5\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 10.9748 - mae: 10.9748\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f37590e6f90>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dVgp_NSt9Vxz",
        "outputId": "ddf70133-ff7b-4962-9dc4-34c02cfc573c"
      },
      "source": [
        "# Check out inputs and output\n",
        "X, y"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(8,), dtype=float64, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.])>,\n",
              " <tf.Tensor: shape=(8,), dtype=float64, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.])>)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vza2_QCi-Uds",
        "outputId": "e931851c-edb2-49bf-cf5a-2d122c147cc6"
      },
      "source": [
        "y_pred = model.predict([17.0])\n",
        "y_pred"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[12.716021]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YrBLwKxS_nCA"
      },
      "source": [
        "### Improving our model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dJ-Gs-I3_B6e",
        "outputId": "98fb1aa2-9e8b-4206-8061-69af3d29ebc4"
      },
      "source": [
        " # Rebuild the model by improving\n",
        "\n",
        " #1. Create a model again\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(1),\n",
        "    \n",
        "])\n",
        "\n",
        " #2. recompile the model\n",
        "model.compile(loss=tf.keras.losses.mae,optimizer=tf.keras.optimizers.SGD(), \n",
        "              metrics=[\"mae\"]) # mae is for mean absolute error gd gradient descent\n",
        "\n",
        "\n",
        "# 3 Fit the model and increase the epochs(and training it longer)\n",
        "model.fit(tf.expand_dims(X,axis=-1), y,epochs=100)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 1s 664ms/step - loss: 21.8432 - mae: 21.8432\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 21.4501 - mae: 21.4501\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 21.0570 - mae: 21.0570\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 20.6638 - mae: 20.6638\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 20.3208 - mae: 20.3208\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 20.0396 - mae: 20.0396\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 19.7583 - mae: 19.7583\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 19.4771 - mae: 19.4771\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 19.1958 - mae: 19.1958\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 18.9146 - mae: 18.9146\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 18.6333 - mae: 18.6333\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 18.3521 - mae: 18.3521\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 18.0708 - mae: 18.0708\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 17.7896 - mae: 17.7896\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 17.5083 - mae: 17.5083\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 17.2271 - mae: 17.2271\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 16.9458 - mae: 16.9458\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 16.6646 - mae: 16.6646\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 16.3833 - mae: 16.3833\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 16.1021 - mae: 16.1021\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 15.8208 - mae: 15.8208\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 15.5396 - mae: 15.5396\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 15.2583 - mae: 15.2583\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 14.9771 - mae: 14.9771\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 14.7122 - mae: 14.7122\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 14.5797 - mae: 14.5797\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 14.4472 - mae: 14.4472\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 14.3147 - mae: 14.3147\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 14.1822 - mae: 14.1822\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 14.0497 - mae: 14.0497\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 13.9172 - mae: 13.9172\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 13.7847 - mae: 13.7847\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 13.6522 - mae: 13.6522\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 13.5197 - mae: 13.5197\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 13.3872 - mae: 13.3872\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 13.2547 - mae: 13.2547\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 13.1222 - mae: 13.1222\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 12.9897 - mae: 12.9897\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 12.8572 - mae: 12.8572\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 12.7247 - mae: 12.7247\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 12.5922 - mae: 12.5922\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 12.4597 - mae: 12.4597\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 12.3272 - mae: 12.3272\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 12.1947 - mae: 12.1947\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 12.0622 - mae: 12.0622\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 11.9297 - mae: 11.9297\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 11.7972 - mae: 11.7972\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 11.6647 - mae: 11.6647\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 11.5322 - mae: 11.5322\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 11.3997 - mae: 11.3997\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 11.2672 - mae: 11.2672\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 11.1347 - mae: 11.1347\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 11.0022 - mae: 11.0022\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 10.8697 - mae: 10.8697\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 10.7372 - mae: 10.7372\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 10.6047 - mae: 10.6047\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 10.4722 - mae: 10.4722\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 10.3397 - mae: 10.3397\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 10.2072 - mae: 10.2072\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 10.0747 - mae: 10.0747\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 9.9422 - mae: 9.9422\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 9.8097 - mae: 9.8097\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 9.6772 - mae: 9.6772\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 9.5447 - mae: 9.5447\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 9.4122 - mae: 9.4122\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 9.2797 - mae: 9.2797\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 9.1472 - mae: 9.1472\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 9.0147 - mae: 9.0147\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 8.8822 - mae: 8.8822\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 8.7497 - mae: 8.7497\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 8.6172 - mae: 8.6172\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 8.4847 - mae: 8.4847\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 8.3522 - mae: 8.3522\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 8.2197 - mae: 8.2197\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.0872 - mae: 8.0872\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.9547 - mae: 7.9547\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 7.8222 - mae: 7.8222\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.6897 - mae: 7.6897\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.5572 - mae: 7.5572\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.4247 - mae: 7.4247\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.2922 - mae: 7.2922\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 7.1597 - mae: 7.1597\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.0272 - mae: 7.0272\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.9300 - mae: 6.9300\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.9244 - mae: 6.9244\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.9188 - mae: 6.9188\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.9131 - mae: 6.9131\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.9075 - mae: 6.9075\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.9019 - mae: 6.9019\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 6.8963 - mae: 6.8963\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 6.8906 - mae: 6.8906\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 6.8850 - mae: 6.8850\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.8794 - mae: 6.8794\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 6.8738 - mae: 6.8738\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.8681 - mae: 6.8681\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.8625 - mae: 6.8625\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 6.8569 - mae: 6.8569\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 6.8513 - mae: 6.8513\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 6.8456 - mae: 6.8456\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 6.8400 - mae: 6.8400\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f7f267e8550>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MduXXYgxMDOd",
        "outputId": "0a907c9e-d4c7-4790-ab81-e2be970c9190"
      },
      "source": [
        "# Checking the progression of the model\n",
        "model.predict([17.0])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[29.278933]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "47f2Kqf5M_5i",
        "outputId": "115aea8b-6dbb-4785-e469-e65e287ad23f"
      },
      "source": [
        "# Rebuild the model for the third time by adding a new layer and activation\n",
        "\n",
        " #1. Create a model again\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(100, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(100, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(1)\n",
        "    \n",
        "])\n",
        "\n",
        " #2. recompile the model\n",
        "model.compile(loss=tf.keras.losses.mae,optimizer=tf.keras.optimizers.SGD(), \n",
        "              metrics=[\"mae\"]) # mae is for mean absolute error gd gradient descent\n",
        "\n",
        "\n",
        "# 3 Fit the model and keeping the epochs\n",
        "model.fit(tf.expand_dims(X,axis=-1), y,epochs=100)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 0s 314ms/step - loss: 13.6105 - mae: 13.6105\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 13.0629 - mae: 13.0629\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 12.5267 - mae: 12.5267\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 11.9797 - mae: 11.9797\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 11.3959 - mae: 11.3959\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 10.7758 - mae: 10.7758\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 10.0915 - mae: 10.0915\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 9.3167 - mae: 9.3167\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.4407 - mae: 8.4407\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.4080 - mae: 7.4080\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.1743 - mae: 6.1743\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.7011 - mae: 4.7011\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.9459 - mae: 3.9459\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.9746 - mae: 3.9746\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.9552 - mae: 3.9552\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.9381 - mae: 3.9381\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.9650 - mae: 3.9650\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.9009 - mae: 3.9009\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.9753 - mae: 3.9753\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.8662 - mae: 3.8662\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 4.0108 - mae: 4.0108\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.8783 - mae: 3.8783\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.9564 - mae: 3.9564\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.8888 - mae: 3.8888\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.9184 - mae: 3.9184\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.9000 - mae: 3.9000\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.8796 - mae: 3.8796\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.9117 - mae: 3.9117\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.8486 - mae: 3.8486\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.9480 - mae: 3.9480\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.8184 - mae: 3.8184\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.9308 - mae: 3.9308\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.8299 - mae: 3.8299\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.8914 - mae: 3.8914\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 3.8421 - mae: 3.8421\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.8511 - mae: 3.8511\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.8547 - mae: 3.8547\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.8226 - mae: 3.8226\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.8912 - mae: 3.8912\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.7641 - mae: 3.7641\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 3.8973 - mae: 3.8973\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.7765 - mae: 3.7765\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.8560 - mae: 3.8560\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.7896 - mae: 3.7896\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.8141 - mae: 3.8141\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.8033 - mae: 3.8033\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.7864 - mae: 3.7864\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.8417 - mae: 3.8417\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.7217 - mae: 3.7217\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.8555 - mae: 3.8555\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.7286 - mae: 3.7286\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.8129 - mae: 3.8129\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.7428 - mae: 3.7428\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.7694 - mae: 3.7694\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.7578 - mae: 3.7578\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.7410 - mae: 3.7410\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.7972 - mae: 3.7972\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.6735 - mae: 3.6735\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.8124 - mae: 3.8124\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.6875 - mae: 3.6875\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.7633 - mae: 3.7633\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.7028 - mae: 3.7028\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.7178 - mae: 3.7178\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.7187 - mae: 3.7187\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 3.6877 - mae: 3.6877\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.7591 - mae: 3.7591\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.6368 - mae: 3.6368\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.7520 - mae: 3.7520\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.6525 - mae: 3.6525\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.7053 - mae: 3.7053\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.6689 - mae: 3.6689\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.6577 - mae: 3.6577\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.6860 - mae: 3.6860\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.6236 - mae: 3.6236\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.7272 - mae: 3.7272\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.6053 - mae: 3.6053\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 3.6882 - mae: 3.6882\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.6218 - mae: 3.6218\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.6388 - mae: 3.6388\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.6392 - mae: 3.6392\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.5885 - mae: 3.5885\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.6570 - mae: 3.6570\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.5491 - mae: 3.5491\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.6572 - mae: 3.6572\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.5838 - mae: 3.5838\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.6055 - mae: 3.6055\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.6021 - mae: 3.6021\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.5530 - mae: 3.5530\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.6213 - mae: 3.6213\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.5013 - mae: 3.5013\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.6480 - mae: 3.6480\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 3.5432 - mae: 3.5432\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.5768 - mae: 3.5768\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.5619 - mae: 3.5619\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.5226 - mae: 3.5226\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.5816 - mae: 3.5816\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.4679 - mae: 3.4679\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 3.6019 - mae: 3.6019\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.4812 - mae: 3.4812\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.5574 - mae: 3.5574\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f7f2677d110>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K_1OZA--OC6b",
        "outputId": "4891546e-f130-4d2c-d70b-fda13028239a"
      },
      "source": [
        "# Checking the progression of the model again\n",
        "model.predict([17.0])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[32.6719]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I276PbjROHiV",
        "outputId": "e86229ad-16eb-4e25-a39e-7ff80f94eac0"
      },
      "source": [
        "# An other change to our model(one extra layer with 100 unit)\n",
        " #1. Create a model again\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(100, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(1)\n",
        "    \n",
        "])\n",
        "\n",
        " #2. recompile the model\n",
        "model.compile(loss=\"mae\",\n",
        "              optimizer=tf.keras.optimizers.SGD(), \n",
        "              metrics=[\"mae\"])\n",
        "\n",
        "\n",
        "# 3 Fit the model and keeping the epochs\n",
        "model.fit(tf.expand_dims(X,axis=-1), y,epochs=100)\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 0s 236ms/step - loss: 13.9888 - mae: 13.9888\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 13.3662 - mae: 13.3662\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 12.7467 - mae: 12.7467\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 12.1223 - mae: 12.1223\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 11.4839 - mae: 11.4839\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 10.8340 - mae: 10.8340\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 10.1650 - mae: 10.1650\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 9.4763 - mae: 9.4763\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 8.7550 - mae: 8.7550\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.0039 - mae: 8.0039\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.2030 - mae: 7.2030\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.3464 - mae: 6.3464\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.4257 - mae: 5.4257\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 4.4958 - mae: 4.4958\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.3548 - mae: 4.3548\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.2110 - mae: 4.2110\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.1132 - mae: 4.1132\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 4.0972 - mae: 4.0972\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 4.0330 - mae: 4.0330\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.9834 - mae: 3.9834\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.9517 - mae: 3.9517\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.8905 - mae: 3.8905\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.9376 - mae: 3.9376\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.8681 - mae: 3.8681\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.9409 - mae: 3.9409\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.8806 - mae: 3.8806\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.9219 - mae: 3.9219\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.8904 - mae: 3.8904\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.8961 - mae: 3.8961\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 3.8979 - mae: 3.8979\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 3.8701 - mae: 3.8701\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.9056 - mae: 3.9056\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.8439 - mae: 3.8439\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.9155 - mae: 3.9155\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.8514 - mae: 3.8514\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.9004 - mae: 3.9004\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.8592 - mae: 3.8592\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.8742 - mae: 3.8742\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.8671 - mae: 3.8671\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.8479 - mae: 3.8479\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.8750 - mae: 3.8750\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.8214 - mae: 3.8214\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.8893 - mae: 3.8893\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.8214 - mae: 3.8214\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.8774 - mae: 3.8774\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.8293 - mae: 3.8293\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 3.8509 - mae: 3.8509\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.8374 - mae: 3.8374\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.8243 - mae: 3.8243\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.8455 - mae: 3.8455\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.8013 - mae: 3.8013\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.8610 - mae: 3.8610\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.7925 - mae: 3.7925\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.8531 - mae: 3.8531\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.8006 - mae: 3.8006\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.8262 - mae: 3.8262\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 3.8089 - mae: 3.8089\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.7994 - mae: 3.7994\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.8177 - mae: 3.8177\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.7790 - mae: 3.7790\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.8329 - mae: 3.8329\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.7646 - mae: 3.7646\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.8275 - mae: 3.8275\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.7730 - mae: 3.7730\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.8003 - mae: 3.8003\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.7815 - mae: 3.7815\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.7731 - mae: 3.7731\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.7943 - mae: 3.7943\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.7525 - mae: 3.7525\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.8059 - mae: 3.8059\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.7379 - mae: 3.7379\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.8006 - mae: 3.8006\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.7465 - mae: 3.7465\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.7731 - mae: 3.7731\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.7552 - mae: 3.7552\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.7469 - mae: 3.7469\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 3.7711 - mae: 3.7711\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.7246 - mae: 3.7246\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 3.7799 - mae: 3.7799\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.7122 - mae: 3.7122\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.7723 - mae: 3.7723\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.7209 - mae: 3.7209\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.7445 - mae: 3.7445\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.7298 - mae: 3.7298\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.7215 - mae: 3.7215\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.7460 - mae: 3.7460\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.6952 - mae: 3.6952\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.7550 - mae: 3.7550\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.6875 - mae: 3.6875\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.7426 - mae: 3.7426\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.6965 - mae: 3.6965\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.7145 - mae: 3.7145\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.7067 - mae: 3.7067\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.6929 - mae: 3.6929\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.7219 - mae: 3.7219\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.6646 - mae: 3.6646\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 3.7311 - mae: 3.7311\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.6638 - mae: 3.6638\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.7117 - mae: 3.7117\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 3.6729 - mae: 3.6729\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f7f26110310>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U1UFX6FRSkOw",
        "outputId": "00bae502-6d9c-4189-e2be-d07c0c188af7"
      },
      "source": [
        "# Let'stry to make a production\n",
        "model.predict([17.0])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[31.422806]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rt5W6tc7TALE",
        "outputId": "738f5a5b-8239-4f9f-a126-41940966f7e7"
      },
      "source": [
        "# An other change to our model()\n",
        " #1. Create a model again\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(500, activation=None),\n",
        "    tf.keras.layers.Dense(1)\n",
        "    \n",
        "])\n",
        "\n",
        " #2. recompile the model\n",
        "model.compile(loss=\"mae\",\n",
        "              optimizer=tf.keras.optimizers.SGD(), \n",
        "              metrics=[\"mae\"])\n",
        "\n",
        "\n",
        "# 3 Fit the model and keeping the epochs\n",
        "model.fit(tf.expand_dims(X,axis=-1), y,epochs=100)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 0s 237ms/step - loss: 13.2275 - mae: 13.2275\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 12.7091 - mae: 12.7091\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 12.1880 - mae: 12.1880\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 11.6613 - mae: 11.6613\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 11.1265 - mae: 11.1265\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 10.5806 - mae: 10.5806\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 10.0210 - mae: 10.0210\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 9.4447 - mae: 9.4447\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 8.8488 - mae: 8.8488\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 8.2303 - mae: 8.2303\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.5859 - mae: 7.5859\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 7.2156 - mae: 7.2156\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.1943 - mae: 7.1943\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 7.1730 - mae: 7.1730\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 7.1517 - mae: 7.1517\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 7.1303 - mae: 7.1303\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.1088 - mae: 7.1088\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.0873 - mae: 7.0873\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.0657 - mae: 7.0657\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 7.0441 - mae: 7.0441\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 7.0224 - mae: 7.0224\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 7.0006 - mae: 7.0006\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.9787 - mae: 6.9787\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 6.9567 - mae: 6.9567\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 6.9347 - mae: 6.9347\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 6.9125 - mae: 6.9125\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.8903 - mae: 6.8903\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 6.8680 - mae: 6.8680\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.8455 - mae: 6.8455\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 6.8230 - mae: 6.8230\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 6.8003 - mae: 6.8003\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.7776 - mae: 6.7776\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 6.7547 - mae: 6.7547\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.7434 - mae: 6.7434\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 6.7255 - mae: 6.7255\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 6.7028 - mae: 6.7028\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.6801 - mae: 6.6801\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 6.6571 - mae: 6.6571\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 6.6341 - mae: 6.6341\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.6109 - mae: 6.6109\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 6.5876 - mae: 6.5876\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 6.5641 - mae: 6.5641\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.5404 - mae: 6.5404\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 6.5166 - mae: 6.5166\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 6.4927 - mae: 6.4927\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 6.4686 - mae: 6.4686\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.4443 - mae: 6.4443\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 6.4198 - mae: 6.4198\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 6.3952 - mae: 6.3952\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.3704 - mae: 6.3704\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 6.3453 - mae: 6.3453\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 6.3202 - mae: 6.3202\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 6.2948 - mae: 6.2948\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 6.2692 - mae: 6.2692\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 6.2434 - mae: 6.2434\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 6.2354 - mae: 6.2354\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 6.2144 - mae: 6.2144\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 6.1886 - mae: 6.1886\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.1625 - mae: 6.1625\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 6.1363 - mae: 6.1363\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 6.1098 - mae: 6.1098\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.0831 - mae: 6.0831\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 6.0561 - mae: 6.0561\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.0289 - mae: 6.0289\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 6.0015 - mae: 6.0015\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 5.9738 - mae: 5.9738\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.9459 - mae: 5.9459\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.9177 - mae: 5.9177\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.8892 - mae: 5.8892\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 5.8605 - mae: 5.8605\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 5.8315 - mae: 5.8315\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.8022 - mae: 5.8022\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.7793 - mae: 5.7793\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 5.7736 - mae: 5.7736\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 5.8845 - mae: 5.8845\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 5.7077 - mae: 5.7077\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 5.6774 - mae: 5.6774\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 5.6469 - mae: 5.6469\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 5.6160 - mae: 5.6160\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 5.5848 - mae: 5.5848\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 5.5533 - mae: 5.5533\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 5.5215 - mae: 5.5215\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 5.4893 - mae: 5.4893\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.4568 - mae: 5.4568\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.4351 - mae: 5.4351\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 5.4672 - mae: 5.4672\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 5.5443 - mae: 5.5443\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 5.3518 - mae: 5.3518\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 5.3180 - mae: 5.3180\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 5.2839 - mae: 5.2839\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 5.2494 - mae: 5.2494\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.2145 - mae: 5.2145\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 5.1792 - mae: 5.1792\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.1435 - mae: 5.1435\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 5.1074 - mae: 5.1074\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 5.0792 - mae: 5.0792\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 5.1688 - mae: 5.1688\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 5.1918 - mae: 5.1918\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 4.9902 - mae: 4.9902\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 4.9525 - mae: 4.9525\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f7f25811b90>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lHu0L04XWMTk",
        "outputId": "d101cc5a-5ed0-4dbd-bf90-aa0158c8df95"
      },
      "source": [
        "# Let's try an other prediction\n",
        "model.predict([17.0])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[29.397879]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AGdrN1HsRT5Z",
        "outputId": "5d4a8566-c4fe-49fd-c2d2-6b4c200cb0c5"
      },
      "source": [
        "# An other change to our model()\n",
        " #1. Create a model again\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(500, activation=None),\n",
        "    tf.keras.layers.Dense(1)\n",
        "    \n",
        "])\n",
        "\n",
        " #2. recompile the model\n",
        "model.compile(loss=\"mae\",\n",
        "              optimizer=tf.keras.optimizers.Adam(), \n",
        "              metrics=[\"mae\"])\n",
        "\n",
        "\n",
        "# 3 Fit the model and keeping the epochs\n",
        "model.fit(tf.expand_dims(X,axis=-1), y,epochs=100)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 0s 306ms/step - loss: 13.6615 - mae: 13.6615\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 13.4531 - mae: 13.4531\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 13.2451 - mae: 13.2451\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 13.0372 - mae: 13.0372\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 12.8294 - mae: 12.8294\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 12.6215 - mae: 12.6215\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 12.4135 - mae: 12.4135\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 12.2053 - mae: 12.2053\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 11.9967 - mae: 11.9967\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 11.7876 - mae: 11.7876\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 11.5780 - mae: 11.5780\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 11.3677 - mae: 11.3677\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 11.1565 - mae: 11.1565\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 10.9443 - mae: 10.9443\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 10.7310 - mae: 10.7310\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 10.5165 - mae: 10.5165\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 10.3005 - mae: 10.3005\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 10.0829 - mae: 10.0829\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 9.8635 - mae: 9.8635\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 9.6422 - mae: 9.6422\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 9.4188 - mae: 9.4188\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 9.1931 - mae: 9.1931\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 8.9649 - mae: 8.9649\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.7342 - mae: 8.7342\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.5006 - mae: 8.5006\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.2641 - mae: 8.2641\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 8.0244 - mae: 8.0244\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.7815 - mae: 7.7815\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 7.5351 - mae: 7.5351\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 7.2850 - mae: 7.2850\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 7.0312 - mae: 7.0312\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 6.7978 - mae: 6.7978\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 6.7685 - mae: 6.7685\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.7394 - mae: 6.7394\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 6.7129 - mae: 6.7129\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 6.8003 - mae: 6.8003\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 6.8620 - mae: 6.8620\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.9002 - mae: 6.9002\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 6.9173 - mae: 6.9173\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 6.9153 - mae: 6.9153\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.8963 - mae: 6.8963\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 6.8621 - mae: 6.8621\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 6.8144 - mae: 6.8144\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 6.7547 - mae: 6.7547\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 6.6846 - mae: 6.6846\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.6053 - mae: 6.6053\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.5180 - mae: 6.5180\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 6.4423 - mae: 6.4423\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 6.4262 - mae: 6.4262\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.4090 - mae: 6.4090\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 6.3909 - mae: 6.3909\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 6.3719 - mae: 6.3719\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 6.3520 - mae: 6.3520\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.3314 - mae: 6.3314\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.3101 - mae: 6.3101\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.2880 - mae: 6.2880\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 6.2652 - mae: 6.2652\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 6.2417 - mae: 6.2417\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.2175 - mae: 6.2175\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 6.1927 - mae: 6.1927\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 6.1787 - mae: 6.1787\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.1390 - mae: 6.1390\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.1103 - mae: 6.1103\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.0811 - mae: 6.0811\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.0514 - mae: 6.0514\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 6.0213 - mae: 6.0213\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.9907 - mae: 5.9907\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.9595 - mae: 5.9595\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.9279 - mae: 5.9279\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.8957 - mae: 5.8957\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.8630 - mae: 5.8630\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.8297 - mae: 5.8297\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 5.7959 - mae: 5.7959\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.7615 - mae: 5.7615\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.7264 - mae: 5.7264\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 5.6908 - mae: 5.6908\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.6546 - mae: 5.6546\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 5.6177 - mae: 5.6177\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 5.5802 - mae: 5.5802\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 5.5420 - mae: 5.5420\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.5127 - mae: 5.5127\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.4809 - mae: 5.4809\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 5.4323 - mae: 5.4323\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.3968 - mae: 5.3968\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.3601 - mae: 5.3601\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 5.3223 - mae: 5.3223\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 5.2834 - mae: 5.2834\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.2434 - mae: 5.2434\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 5.2024 - mae: 5.2024\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 5.1603 - mae: 5.1603\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.1204 - mae: 5.1204\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 5.0764 - mae: 5.0764\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 5.0343 - mae: 5.0343\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.9910 - mae: 4.9910\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 4.9464 - mae: 4.9464\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 4.9006 - mae: 4.9006\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 4.8535 - mae: 4.8535\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 4.8053 - mae: 4.8053\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 4.7664 - mae: 4.7664\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.7090 - mae: 4.7090\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f7f22da2790>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f3FwxQVNRwwQ",
        "outputId": "89860fc2-1ff8-4698-d6d8-42dab66720d9"
      },
      "source": [
        "# An other change to our model()\n",
        " #1. Create a model again by increasing the learning rate of ADAM\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(500, activation=None),\n",
        "    tf.keras.layers.Dense(1)\n",
        "    \n",
        "])\n",
        "\n",
        " #2. recompile the model\n",
        "model.compile(loss=\"mae\",\n",
        "              optimizer=tf.keras.optimizers.Adam(learning_rate=0.01), \n",
        "              metrics=[\"mae\"])\n",
        "\n",
        "\n",
        "# 3 Fit the model and keeping the epochs\n",
        "model.fit(tf.expand_dims(X,axis=-1), y,epochs=100)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 0s 270ms/step - loss: 13.2369 - mae: 13.2369\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 11.0169 - mae: 11.0169\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 8.7629 - mae: 8.7629\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.8271 - mae: 6.8271\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.2052 - mae: 8.2052\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.4396 - mae: 8.4396\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.7324 - mae: 7.7324\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.6791 - mae: 6.6791\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 6.0136 - mae: 6.0136\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.2309 - mae: 6.2309\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.3349 - mae: 6.3349\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.0594 - mae: 6.0594\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.4684 - mae: 5.4684\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 4.9273 - mae: 4.9273\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.9474 - mae: 4.9474\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 5.0014 - mae: 5.0014\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 4.7516 - mae: 4.7516\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.1222 - mae: 4.1222\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.4591 - mae: 3.4591\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.4584 - mae: 3.4584\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.4343 - mae: 3.4343\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.0222 - mae: 3.0222\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.2358 - mae: 2.2358\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.3090 - mae: 1.3090\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.2573 - mae: 1.2573\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7305 - mae: 0.7305\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6631 - mae: 0.6631\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.2736 - mae: 1.2736\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.3310 - mae: 1.3310\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.5906 - mae: 1.5906\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.6748 - mae: 1.6748\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.2462 - mae: 1.2462\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.1370 - mae: 1.1370\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.8392 - mae: 0.8392\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.4079 - mae: 0.4079\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1006 - mae: 0.1006\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6329 - mae: 0.6329\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7683 - mae: 0.7683\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5468 - mae: 0.5468\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.7968 - mae: 0.7968\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6602 - mae: 0.6602\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4019 - mae: 0.4019\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.3035 - mae: 0.3035\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.2415 - mae: 0.2415\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.3199 - mae: 0.3199\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.4852 - mae: 0.4852\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.3613 - mae: 0.3613\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.3666 - mae: 0.3666\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.3522 - mae: 0.3522\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2896 - mae: 0.2896\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.3712 - mae: 0.3712\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.1130 - mae: 0.1130\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0849 - mae: 0.0849\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4424 - mae: 0.4424\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.3510 - mae: 0.3510\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.3212 - mae: 0.3212\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.3688 - mae: 0.3688\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1348 - mae: 0.1348\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1016 - mae: 0.1016\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.3413 - mae: 0.3413\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.2288 - mae: 0.2288\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.3688 - mae: 0.3688\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.3065 - mae: 0.3065\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.2559 - mae: 0.2559\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.2522 - mae: 0.2522\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.2673 - mae: 0.2673\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.2798 - mae: 0.2798\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.2162 - mae: 0.2162\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.2533 - mae: 0.2533\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.1880 - mae: 0.1880\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1062 - mae: 0.1062\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.3966 - mae: 0.3966\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.3147 - mae: 0.3147\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.2648 - mae: 0.2648\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2933 - mae: 0.2933\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1648 - mae: 0.1648\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0836 - mae: 0.0836\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.4735 - mae: 0.4735\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.4907 - mae: 0.4907\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0481 - mae: 0.0481\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7418 - mae: 0.7418\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.9477 - mae: 0.9477\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6600 - mae: 0.6600\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.2373 - mae: 0.2373\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5169 - mae: 0.5169\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.3579 - mae: 0.3579\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.2320 - mae: 0.2320\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.3157 - mae: 0.3157\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.2214 - mae: 0.2214\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1303 - mae: 0.1303\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.3276 - mae: 0.3276\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.3138 - mae: 0.3138\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.3688 - mae: 0.3688\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.3760 - mae: 0.3760\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1225 - mae: 0.1225\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0717 - mae: 0.0717\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.2134 - mae: 0.2134\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1463 - mae: 0.1463\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0994 - mae: 0.0994\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1946 - mae: 0.1946\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f7f22cfaa10>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "auMzwVINSOvF",
        "outputId": "ae7ac23f-6d21-492d-f2ee-233e2784cff3"
      },
      "source": [
        "#let's make a prediction\n",
        "model.predict([17.0])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f7f22c81cb0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[27.054007]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_cw4i7_aStzw",
        "outputId": "37e7ab95-41d3-4610-b3e5-0b00cdaa1b71"
      },
      "source": [
        "#let's make an other prediction\n",
        "model.predict([19.0])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[29.044458]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6w1ByAdNT1EN"
      },
      "source": [
        "### Evaluating a Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rIETa0tqS0km",
        "outputId": "ddb152f5-ee13-421e-a734-f32d3d13c36d"
      },
      "source": [
        "# Make a bigger dataset\n",
        "X = tf.range(-100, 100, 4)\n",
        "X"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(50,), dtype=int32, numpy=\n",
              "array([-100,  -96,  -92,  -88,  -84,  -80,  -76,  -72,  -68,  -64,  -60,\n",
              "        -56,  -52,  -48,  -44,  -40,  -36,  -32,  -28,  -24,  -20,  -16,\n",
              "        -12,   -8,   -4,    0,    4,    8,   12,   16,   20,   24,   28,\n",
              "         32,   36,   40,   44,   48,   52,   56,   60,   64,   68,   72,\n",
              "         76,   80,   84,   88,   92,   96], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5n8J5crTW0Cz",
        "outputId": "4b085144-4a6c-4625-d8c0-c679ef1c207b"
      },
      "source": [
        "# Make labels for the dataset\n",
        "y = X + 10\n",
        "y"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(50,), dtype=int32, numpy=\n",
              "array([-90, -86, -82, -78, -74, -70, -66, -62, -58, -54, -50, -46, -42,\n",
              "       -38, -34, -30, -26, -22, -18, -14, -10,  -6,  -2,   2,   6,  10,\n",
              "        14,  18,  22,  26,  30,  34,  38,  42,  46,  50,  54,  58,  62,\n",
              "        66,  70,  74,  78,  82,  86,  90,  94,  98, 102, 106], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "xrDbm0XfXUuD",
        "outputId": "b7e86fc3-aec8-4fc4-dd42-59c8905c7677"
      },
      "source": [
        "# Visualize the data\n",
        "import matplotlib.pyplot as plt\n",
        "plt.scatter(X, y)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7f7f22b70b50>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QtimDriHUIXf"
      },
      "source": [
        "#### Creating the 3 sets(training, validation and Test sets)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-YaRdAChX4KN",
        "outputId": "90ed47e9-1b53-48ff-c5be-4db6ae34eb65"
      },
      "source": [
        "# Split the data into train and test sets\n",
        "X_train = X[:40] # first 40 are training samples (80% of the data)\n",
        "y_train = y[:40]\n",
        "\n",
        "X_test = X[40:] # last 10 are testting samples (20% of the data)\n",
        "y_test = y[40:]\n",
        "\n",
        "len(X_train), len(X_test), len(y_train), len(y_test)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(40, 10, 40, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mf17uZe3XD9e"
      },
      "source": [
        "### Visualizing the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "tkhWqdiKVjbd",
        "outputId": "8c5a84a7-b08c-4a55-b4d2-673c07d04a9e"
      },
      "source": [
        "plt.figure(figsize=(10, 7))\n",
        "# Plot training data in blue\n",
        "plt.scatter(X_train, y_train, c=\"b\", label=\"Training data\")\n",
        "# Plot test data in green\n",
        "plt.scatter(X_test, y_test, c=\"g\", label=\"Testing data\")\n",
        "# show a legend\n",
        "plt.legend();"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gNkeh95yYMFh"
      },
      "source": [
        "# Building a NN for our data\n",
        "\n",
        "# Create a model\n",
        "model = tf.keras.Sequential([\n",
        "          tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss=tf.keras.losses.mae,\n",
        "              optimizer=tf.keras.optimizers.SGD(),\n",
        "              metrics=[\"mae\"])\n",
        "\n",
        "# fit the model\n",
        "#model.fit(X_train, y_train, epochs=100)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ghzEVzhObuhw"
      },
      "source": [
        "### Visualizing the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L0VGjut_boRo",
        "outputId": "22e280c6-0986-485a-a1db-e65939be058f"
      },
      "source": [
        "# creating a model which will builds automatically by defining the input_shape argument\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# create a model (same as above)\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(1, input_shape=[1])\n",
        "])\n",
        "\n",
        "# compile the model\n",
        "model.compile(loss=tf.keras.losses.mae,\n",
        "              optimizer=tf.keras.optimizers.SGD(),\n",
        "              metrics=[\"mae\"])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_14 (Dense)            (None, 1)                 2         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2\n",
            "Trainable params: 2\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CWPN3vM0eF9u",
        "outputId": "866fcd30-178e-4a2c-a9c1-73bbd7213fdc"
      },
      "source": [
        "# Let's fit our model to the training data\n",
        "model.fit(X_train, y_train, epochs=100, verbose=0)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f7f25eafcd0>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_cYYaFBzA6E"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}